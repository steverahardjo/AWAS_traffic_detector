{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf, col, window\n",
    "from pyspark.sql.types import StringType\n",
    "from util import kafkaConsumer\n",
    "import pandas as pd\n",
    "from operations import SparkInst\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_job=SparkInst(\"AWAS SYSTEM\", 5, \"violations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/pyspark/sql/pandas/conversion.py:474: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for column, series in pdf.iteritems():\n",
      "/opt/conda/lib/python3.8/site-packages/pyspark/sql/pandas/conversion.py:486: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for column, series in pdf.iteritems():\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_pd = pd.read_csv(\"data/camera.csv\")\n",
    "if '_id' in df_pd.columns:\n",
    "    df_pd.drop(columns=['_id'], inplace=True)\n",
    "spark_df = spark_job.get_session().createDataFrame(df_pd)\n",
    "\n",
    "# Step 3: Broadcast your speed limit map\n",
    "speed_limit_map = {row['camera_id']: row['speed_limit'] for row in spark_df.select(\"camera_id\", \"speed_limit\").collect()}\n",
    "broadcast_map = spark_job.essentialData_broadcast(spark_df)\n",
    "# Step 4: Define your UDF using broadcast variable\n",
    "def mark_speeding(camera_id:str, speed:float, ops:str):\n",
    "    limit = broadcast_map.value.get(camera_id)\n",
    "    if limit is not None and ops == \"instant\":\n",
    "        return \"INSTANT_VIOLATION\" if speed > limit else None\n",
    "    elif limit is not None and ops == \"average\":\n",
    "        return \"AVERAGE_VIOLATION\" if speed > limit else None\n",
    "    return \"NONE\"\n",
    "\n",
    "speeding_udf = udf(mark_speeding, StringType())\n",
    "\n",
    "# Step 5: Apply UDF to each streaming dataframe\n",
    "def add_speed_flag(df, ops:str ):\n",
    "    return df.withColumn(\"speed_flag\", speeding_udf(col(\"camera_id\"), col(\"speed_reading\"), ops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import expr, col\n",
    "\n",
    "# Attach Kafka streams\n",
    "stream_a = spark_job.attach_kafka_stream(\"topic_events_a\", \"9092\", \"5 minutes\")\n",
    "stream_b = spark_job.attach_kafka_stream(\"topic_events_b\", \"9092\", \"5 minutes\")\n",
    "stream_c = spark_job.attach_kafka_stream(\"topic_events_c\", \"9092\", \"5 minutes\")\n",
    "\n",
    "# Apply transformation\n",
    "stream_a_flagged = add_speed_flag(stream_a, \"instant\")\n",
    "stream_b_flagged = add_speed_flag(stream_b, \"instant\")\n",
    "stream_c_flagged = add_speed_flag(stream_c, \"instant\")\n",
    "\n",
    "# Duplicate stream_b\n",
    "dup1_b = stream_b_flagged\n",
    "dup2_b = stream_b_flagged\n",
    "\n",
    "# Rename timestamps to avoid conflict\n",
    "stream_a_renamed = stream_a_flagged.withColumnRenamed(\"timestamp\", \"timestamp_start\")\n",
    "stream_b1_renamed = dup1_b.withColumnRenamed(\"timestamp\", \"timestamp_end\")\n",
    "stream_c_renamed = stream_c_flagged.withColumnRenamed(\"timestamp\", \"timestamp_start\")\n",
    "stream_b2_renamed = dup2_b.withColumnRenamed(\"timestamp\", \"timestamp_end\")\n",
    "\n",
    "\n",
    "\n",
    "# Apply watermarks\n",
    "stream_a_watermarked = stream_a_renamed.withWatermark(\"timestamp_a\", \"5 minutes\")\n",
    "stream_b1_watermarked = stream_b1_renamed.withWatermark(\"timestamp_b\", \"5 minutes\")\n",
    "stream_c_watermarked = stream_c_renamed.withWatermark(\"timestamp_c\", \"5 minutes\")\n",
    "stream_b2_watermarked = stream_b2_renamed.withWatermark(\"timestamp_b2\", \"5 minutes\")\n",
    "\n",
    "# Join A and B on car_plate and timestamp condition\n",
    "ab_join = stream_b1_watermarked.join(\n",
    "    stream_a_watermarked,\n",
    "    expr(\"\"\"\n",
    "        stream_b1_watermarked.car_plate = stream_a_watermarked.car_plate AND\n",
    "        timestamp_a > timestamp_b AND\n",
    "        timestamp_a <= timestamp_b + interval 10 minutes\n",
    "    \"\"\"),\n",
    "    \"inner\"\n",
    ").withColumn(\n",
    "    \"avg_measure_speed\",\n",
    "    (col(\"measure_speed_a\") + col(\"measure_speed_b\")) / 2\n",
    ").withColumn(\"speed_flag\", speeding_udf(col(\"camera_id\"), col(\"speed_reading\"), \"average\"))\n",
    "\n",
    "# Join B and C on car_plate and timestamp condition\n",
    "bc_join = stream_b2_watermarked.join(\n",
    "    stream_c_watermarked,\n",
    "    expr(\"\"\"\n",
    "        stream_b2_watermarked.car_plate = stream_c_watermarked.car_plate AND\n",
    "        timestamp_c > timestamp_b2 AND\n",
    "        timestamp_c <= timestamp_b2 + interval 10 minutes\n",
    "    \"\"\"),\n",
    "    \"inner\"\n",
    ").withColumn(\n",
    "    \"avg_measure_speed\",\n",
    "    (col(\"measure_speed_a\") + col(\"measure_speed_b\")) / 2\n",
    ").withColumn(\"speed_flag\", speeding_udf(col(\"camera_id\"), col(\"speed_reading\"), \"average\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ab_join.union(bc_join, window(col(\"timestamp\"), \"24 hours\")).dropna().select()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
