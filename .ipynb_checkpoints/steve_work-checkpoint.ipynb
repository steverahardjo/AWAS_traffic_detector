{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "# add the folder where util.py lives\n",
    "sys.path.append(os.path.join(os.getcwd(), 'fit3182-a2'))\n",
    "sys.path.insert(0, os.path.abspath(os.getcwd()))\n",
    "\n",
    "from pyspark.sql.functions import udf, col, window\n",
    "from pyspark.sql.types import StringType\n",
    "from util import kafkaConsumer\n",
    "import pandas as pd\n",
    "from Operations import SparkInst, DbWriter, ConsoleWriter\n",
    "from pyspark.sql.functions import lit\n",
    "from pyspark.sql.streaming import StreamingQueryException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_job=SparkInst(\"AWAS SYSTEM\", 5, \"violations\")\n",
    "hostip = \"172.22.32.1\"\n",
    "port_spark = 9092\n",
    "port_mongo = 27017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/pyspark/sql/pandas/conversion.py:474: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for column, series in pdf.iteritems():\n",
      "/opt/conda/lib/python3.8/site-packages/pyspark/sql/pandas/conversion.py:486: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for column, series in pdf.iteritems():\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_pd = pd.read_csv(\"data/camera.csv\")\n",
    "if '_id' in df_pd.columns:\n",
    "    df_pd.drop(columns=['_id'], inplace=True)\n",
    "spark_df = spark_job.get_session().createDataFrame(df_pd)\n",
    "\n",
    "# Step 3: Broadcast your speed limit map\n",
    "speed_limit_map = {row['camera_id']: row['speed_limit'] for row in spark_df.select(\"camera_id\", \"speed_limit\").collect()}\n",
    "broadcast_map = spark_job.essentialData_broadcast(spark_df)\n",
    "# Step 4: Define your UDF using broadcast variable\n",
    "def mark_speeding(camera_id:str, speed:float, ops:str):\n",
    "    limit = broadcast_map.value.get(camera_id)\n",
    "    if limit is not None and ops == \"instant\":\n",
    "        return \"INSTANT_VIOLATION\" if speed > limit else None\n",
    "    elif limit is not None and ops == \"average\":\n",
    "        return \"AVERAGE_VIOLATION\" if speed > limit else None\n",
    "    return \"NONE\"\n",
    "\n",
    "speeding_udf = udf(mark_speeding, StringType())\n",
    "\n",
    "# Step 5: Apply UDF to each streaming dataframe\n",
    "def add_speed_flag(df, ops: str):\n",
    "    return df.withColumn(\"speed_flag\", speeding_udf(col(\"camera_id\"), col(\"speed_reading\"), lit(ops)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import expr, col\n",
    "\n",
    "# Attach Kafka streams\n",
    "stream_a = spark_job.attach_kafka_stream(\"camera_event_a\", hostip, \"10 hours\")\n",
    "stream_b = spark_job.attach_kafka_stream(\"camera_event_b\", hostip, \"10 hours\")\n",
    "stream_c = spark_job.attach_kafka_stream(\"camera_event_c\", hostip, \"10 hours\")\n",
    "\n",
    "# Drop unnecessary columns and apply speed flag\n",
    "stream_a_flagged = add_speed_flag(stream_a.drop(\"event_id\"), \"instant\")\n",
    "stream_b_flagged = add_speed_flag(stream_b.drop(\"event_id\"), \"instant\")\n",
    "stream_c_flagged = add_speed_flag(stream_c.drop(\"event_id\"), \"instant\")\n",
    "\n",
    "# Duplicate stream_b for two separate joins\n",
    "dup1_b = stream_b_flagged\n",
    "dup2_b = stream_b_flagged\n",
    "\n",
    "# Rename timestamp and camera_id for join logic\n",
    "stream_a_renamed = stream_a_flagged \\\n",
    "    .withColumnRenamed(\"timestamp\", \"timestamp_start\") \\\n",
    "    .withColumnRenamed(\"camera_id\", \"camera_id_start\")\n",
    "\n",
    "stream_b1_renamed = dup1_b \\\n",
    "    .withColumnRenamed(\"timestamp\", \"timestamp_end\") \\\n",
    "    .withColumnRenamed(\"camera_id\", \"camera_id_end\")\n",
    "\n",
    "stream_c_renamed = stream_c_flagged \\\n",
    "    .withColumnRenamed(\"timestamp\", \"timestamp_end\") \\\n",
    "    .withColumnRenamed(\"camera_id\", \"camera_id_end\")\n",
    "\n",
    "stream_b2_renamed = dup2_b \\\n",
    "    .withColumnRenamed(\"timestamp\", \"timestamp_start\") \\\n",
    "    .withColumnRenamed(\"camera_id\", \"camera_id_start\")\n",
    "\n",
    "# Apply watermarks\n",
    "# stream_a_watermarked = stream_a_renamed.withWatermark(\"sent_at\", \"10 hours\")\n",
    "# stream_b1_watermarked = stream_b1_renamed.withWatermark(\"sent_at\", \"10 hours\")\n",
    "# stream_c_watermarked = stream_c_renamed.withWatermark(\"sent_at\", \"10 hours\")\n",
    "# stream_b2_watermarked = stream_b2_renamed.withWatermark(\"sent_at\", \"10 hours\")\n",
    "\n",
    "# Join A and B\n",
    "ab_join = stream_b1_renamed.alias(\"b\").join(\n",
    "    stream_a_renamed.alias(\"a\"),\n",
    "    expr(\"\"\"\n",
    "      a.car_plate = b.car_plate AND\n",
    "      b.timestamp_end BETWEEN a.timestamp_start AND a.timestamp_start + INTERVAL 10 MINUTES\n",
    "    \"\"\"),\n",
    "    \"inner\"\n",
    ")\n",
    "\n",
    "# ab_join = stream_b1_renamed.alias(\"b\").join(\n",
    "#     stream_a_renamed.alias(\"a\"),\n",
    "#     (\n",
    "#         (col(\"a.car_plate\") == col(\"b.car_plate\")) &\n",
    "#         (col(\"a.timestamp_start\") > col(\"b.timestamp_end\")) &\n",
    "#         (col(\"a.timestamp_start\") <= col(\"b.timestamp_end\") + expr(\"interval 10 minutes\"))\n",
    "#     ),\n",
    "#     \"inner\"\n",
    "# )\n",
    "\n",
    "ab_join = ab_join.withColumn(\n",
    "    \"avg_speed_reading\",\n",
    "    (col(\"a.speed_reading\") + col(\"b.speed_reading\")) / 2\n",
    ").withColumn(\n",
    "    \"speed_flag\",\n",
    "    speeding_udf(col(\"a.camera_id_start\"), col(\"a.speed_reading\"), lit(\"average\"))\n",
    ")\n",
    "\n",
    "# Join B and C\n",
    "bc_join = stream_b2_renamed.alias(\"b\").join(\n",
    "    stream_c_renamed.alias(\"c\"),\n",
    "    expr(\"\"\"\n",
    "      b.car_plate = c.car_plate AND\n",
    "      c.timestamp_end BETWEEN b.timestamp_start AND b.timestamp_start + INTERVAL 10 MINUTES\n",
    "    \"\"\"),\n",
    "    \"inner\"\n",
    ")\n",
    "\n",
    "# Join B and C\n",
    "# bc_join = stream_b2_renamed.alias(\"b\").join(\n",
    "#     stream_c_renamed.alias(\"c\"),\n",
    "#     (\n",
    "#         (col(\"b.car_plate\") == col(\"c.car_plate\")) &\n",
    "#         (col(\"c.timestamp_end\") > col(\"b.timestamp_start\")) &\n",
    "#         (col(\"c.timestamp_end\") <= col(\"b.timestamp_start\") + expr(\"interval 10 minutes\"))\n",
    "#     ),\n",
    "#     \"inner\"\n",
    "# )\n",
    "\n",
    "bc_join = bc_join.withColumn(\n",
    "    \"avg_speed_reading\",\n",
    "    (col(\"b.speed_reading\") + col(\"c.speed_reading\")) / 2\n",
    ").withColumn(\n",
    "    \"speed_flag\",\n",
    "    speeding_udf(col(\"c.camera_id_end\"), col(\"c.speed_reading\"), lit(\"average\"))\n",
    ")\n",
    "\n",
    "res = ab_join.union(bc_join)\n",
    "res = res.dropDuplicates()\n",
    "# ab_join = (\n",
    "#     stream_a_watermarked.alias(\"A\")\n",
    "#     .join(\n",
    "#         stream_b1_watermarked.alias(\"B\"),\n",
    "#         (col(\"A.car_plate\") == col(\"B.car_plate\")),\n",
    "#         how=\"inner\"\n",
    "#     )\n",
    "#     .select(\n",
    "#         col(\"A.*\"),\n",
    "#         col(\"B.batch_id\").alias(\"batch_id_B\"),\n",
    "#         col(\"B.car_plate\").alias(\"car_plate_B\"),\n",
    "#         col(\"B.camera_id\").alias(\"camera_id_B\"),\n",
    "#         col(\"B.timestamp\").alias(\"timestamp_B\"),\n",
    "#         col(\"B.speed_reading\").alias(\"speed_reading_B\"),\n",
    "#         col(\"B.sent_at\").alias(\"timestamp_B\"),\n",
    "#     )\n",
    "# )\n",
    "\n",
    "# ab_join = (\n",
    "#     stream_a_watermarked.alias(\"A\")\n",
    "#       .join(\n",
    "#           stream_b1_watermarked.alias(\"B\"),\n",
    "#           (col(\"A.car_plate\") == col(\"B.car_plate\"))\n",
    "#           & (col(\"A.timestamp\") < col(\"B.timestamp\"))\n",
    "#           & (col(\"A.timestamp\") + expr(\"INTERVAL 5 MINUTES\") >= col(\"B.timestamp\")),\n",
    "#           how=\"inner\"\n",
    "#       )\n",
    "#       .withColumn(\n",
    "#           \"avg_measure_speed\",\n",
    "#           (col(\"A.speed_reading\") + col(\"B.speed_reading\")) / 2\n",
    "#       )\n",
    "#       .withColumn(\n",
    "#           \"speed_flag\",\n",
    "#           speeding_udf(col(\"B.camera_id\"), col(\"avg_measure_speed\"), lit(\"average\"))\n",
    "#       )\n",
    "# )\n",
    "\n",
    "# # Join B and C on car_plate and timestamp condition\n",
    "# bc_join = stream_b2_watermarked.join(\n",
    "#     stream_c_watermarked,\n",
    "#     expr(\"\"\"\n",
    "#         car_plate = car_plate AND\n",
    "#         timestamp_c > timestamp_b2 AND\n",
    "#         timestamp_c <= timestamp_b2 + interval 10 minutes\n",
    "#     \"\"\"),\n",
    "#     \"inner\"\n",
    "# ).withColumn(\n",
    "#     \"avg_measure_speed\",\n",
    "#     (col(\"measure_speed_a\") + col(\"measure_speed_b\")) / 2\n",
    "# ).withColumn(\"speed_flag\", speeding_udf(col(\"camera_id\"), col(\"speed_reading\"), \"average\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:KeyboardInterrupt while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/py4j/clientserver.py\", line 511, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "  File \"/opt/conda/lib/python3.8/socket.py\", line 669, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interrupted by CTRL-C. Stopped query\n"
     ]
    }
   ],
   "source": [
    "spark = ab_join\n",
    "mongo_uri = f\"mongodb://{hostip}:{port_mongo}\"\n",
    "db_name   = \"fit3182_db\"\n",
    "coll_name = \"Violation\"\n",
    "\n",
    "# writer = DbWriter(\n",
    "#     spark,\n",
    "#     mongo_uri,\n",
    "#     mongo_db=   db_name,\n",
    "#     mongo_collection= coll_name\n",
    "# )\n",
    "\n",
    "# writer_stream = (\n",
    "#     ab_join\n",
    "#       .writeStream.format(\"Console\")\n",
    "#       .option(\"checkpointLocation\", \"./stream_checkpoints\")\n",
    "#       .outputMode(\"append\")\n",
    "#       .foreach(ConsoleWriter())     \n",
    "# )\n",
    "\n",
    "writer_stream = (\n",
    "    res\n",
    "      .select(\"*\")\n",
    "      .writeStream\n",
    "      .format(\"console\")\n",
    "      .outputMode(\"append\")\n",
    "      .option(\"checkpointLocation\", \"./stream_checkpoints\") \n",
    ")\n",
    "try:\n",
    "    query = writer_stream.start()\n",
    "    query.awaitTermination()\n",
    "except KeyboardInterrupt:\n",
    "    print('Interrupted by CTRL-C. Stopped query')\n",
    "except StreamingQueryException as exc:\n",
    "    print(exc)\n",
    "finally:\n",
    "    query.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ab_join.union(bc_join, window(col(\"timestamp\"), \"24 hours\")).dropna().select()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
